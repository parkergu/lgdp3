<!DOCTYPE html>
<!--声明了文档类型-->
<html>
<head>
  <!--包含了页面的元数据、引用的样式表（CSS）和脚本（JavaScript）-->
  <meta charset="utf-8">
  <!--设置字符编码为 UTF-8-->
  <meta name="description"
        content="">
  <!--用于搜索引擎优化-->
  <meta name="keywords" content="imitation learning">
  <!--用于搜索引擎优化-->
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!--让页面在移动设备上自适应宽度，提升响应式体验-->
  <title>LGDP3</title>  
  <!--定义浏览器标签页显示的标题-->

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      dataLayer.push(arguments);
    }
    gtag('js', new Date());
    gtag('config', 'G-PYVRSFMDRL');
  </script>
  <!--网站流量统计，通过异步加载和初始化跟踪代码实现数据收集-->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!--多个 link rel="stylesheet" 标签，引入了 Google 字体、Bulma CSS 框架及其扩展（如轮播和滑块）、FontAwesome 图标库、Academicons 学术图标库，以及自定义样式表 index.css-->
  <link rel="icon" href="./static/images/favicon.svg">
  <!--设置了网站的 favicon 图标-->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <!--script 标签，分别引入了 jQuery、FontAwesome 的 JS 文件、Bulma 的轮播和滑块插件，以及自定义的 index.js 脚本-->
</head>


<body>
<section class="hero">
  <!--全宽的横幅（或称为“hero”）区域，通常放置在页面的顶部，用来突出显示重要内容，比如网站标题、标语或关键图像。-->
  <div class="hero-body">
    <!--位于 <section class="hero"> 内，承载该横幅的主体内容（标题、按钮、图片等）。-->
    <div class="container is-max-desktop">
      <!--container:创建一个水平居中、有固定最大宽度的容器。-->
      <!--is-max-desktop:创建一个水平居中的内容区域，其最大宽度被限制为 960px（加上两边的内边距）。-->
      <div class="columns is-centered">
      <!--columns:创建一个列（columns）的容器。-->
      <!--is-centered:内部的所有列（column 元素）在容器内水平居中。-->
        <div class="column has-text-centered">
          <!--定义了这个 div 元素是一个“列”-->
          <!--将该元素内部的所有文本（以及其他行内元素）水平居中-->
          <h1 class="title is-1 publication-title">LGDP3: Local Geometry-Aware 3D Diffusion Policy for Robust Robotic Manipulation</h1>
          <!--h1:HTML 中最高级别的标题标签-->
          <!--title:设定标题的通用样式。is-1:设置为最大号字体。publication-title:进一步调整标题的样式。-->
          <div class="column has-text-centered">
          <!--定义了这个 div 元素是一个“列”-->
          <!--将该元素内部的所有文本（以及其他行内元素）水平居中-->
            <div class="publication-links">
            <!--存放该研究出版物相关的所有重要链接-->
              <!-- Code Link. -->
              <span class="link-block">
              <!--创建一个默认是内联的 span 容器-->
                <a href=""
                   class="external-link button is-normal is-rounded is-dark" disabled>
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <p>
                We will release the code after review.
              </p>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
<!--创建一个大的内容区块，并提供垂直方向的留白-->
  <div class="container is-max-desktop">
  <!--限制内容的宽度并使其水平居中-->
    <div class="columns is-centered">
    <!--建立一个列系统,居中-->
      <div class="column is-full-width">
      <!--定义一个实际存放内容的列,占据其父容器（columns）的全部可用宽度-->
        <h2 class="title is-3 has-text-centered">Abstract</h2>
          <p class="has-text-justified">
              Visual imitation learning has made significant progress in the field of robotic manipulation, but existing methods often fail at tasks requiring precise physical interactions due to a lack of understanding of fine-grained geometric features on object surfaces. We propose LGDP3, a novel visuomotor policy that addresses this by integrating a dedicated local geometric feature extraction module into a 3D diffusion framework. Our perception module analyzes point cloud neighborhoods from a single depth camera to learn critical geometric details (e.g., edges, corners, and planes), which then condition a diffusion model to generate precise and robust action sequences. In comprehensive evaluations across 8 simulated and 2 real-world tasks, LGDP3 consistently outperformed the strong baseline (DP3), achieving a 5.7% relative improvement in simulation and 23.5% in the real world. The policy also demonstrated excellent generalization to variations in object position, appearance, and lighting conditions. These extensive evaluation results highlight the critical role of local geometric feature extraction in learning robust 3D representations for robotic manipulation.
          </p>
        </div>
      </div>
    </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">Video</h2>
        <!--
          <figure class="image is-16by9">
            <iframe class="has-ratio" width="560" height="315" src="https://www.youtube.com/embed/WGfg_L2u_po" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
          </figure>
        -->
        <video width="100%" controls>
          <source src="static/videos/work.mp4" type="video/mp4">
        </video>
        </div>
      </div>
    </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">Motivation</h2>
        <p class="has-text-justified">
          Existing 3D perception-based diffusion policies do not consider extracting fine-grained local geometric features (e.g., edges, corners, and planes). This perception gap, a lack of a detailed understanding of object geometry, leads to policy failures when precise physical interactions are required.
        </p>
        <p class="has-text-justified"></p>
          To address this limitation, we introduce LGDP3, a novel visuomotor policy that explicitly extracts local geometric features from 3D visual data.
        <p class="has-text-justified"></p>
        <img src="static/images/Motivation.png" style="width: 40%; display: block; margin-left: auto; margin-right: auto;">
        <p class="has-text-justified">
           (a) Without Fine-grained 3D-Awareness Perception: Baseline methods lacking local geometric understanding fail at tasks requiring precise physical interactions. (b) With Fine-grained 3D-Awareness Perception: Our method (LGDP3) successfully extracts local geometric details, enabling it to complete these precise manipulation tasks.
        </p>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">Method Overview</h2>
        <img src="static/images/overview.png" style="width: 80%; display: block; margin-left: auto; margin-right: auto;">
        <p class="has-text-centered">
          <strong>Overview of LGDP3</strong>
        </p>
        <p class="has-text-justified">
          Above: (a) The policy is trained end-to-end using expert demonstrations. (b) During evaluation, the trained policy performs closed-loop control using environmental observations. 
          Below: The Perception module extracts a 3D Representation from an input point cloud using an encoder featuring Conv1D layers and our core Local Geometric Feature Extraction module. Simultaneously, it encodes the robot state into a Proprioception Representation via an MLP. The Decision module, a diffusion-based backbone, conditions on these fused representations to generate the final action sequence through a denoising process.
        </p>
        <img src="static/images/local geometric feature extraction.png" style="width: 40%; display: block; margin-left: auto; margin-right: auto; margin-top: 2rem;">
        <p class="has-text-centered">
          <strong>Architecture of the Local Geometric Feature Extraction Module</strong>
        </p>
        <p class="has-text-justified">
          This diagram illustrates the data flow for an input of N=1024 points with C=256 features. The Group block uses K-Nearest Neighbors (KNN) to find K=32 neighbors (a value determined by ablation), resulting in a (1024, 32, 256) tensor. The Pre Feature Extraction block then applies a shared module of Conv1D-ReLU layer. An Aggregate block performs Max Pooling to achieve permutation invariance and reduce the tensor to (1024, 256). Finally, the Post Feature Extraction block applies another Conv1D-ReLU layer to produce the final feature representation.
        </p>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">Real-world Demos</h2>
          <video style="width: 90%; display: block; margin-left: auto; margin-right: auto;" controls>
            <source src="static/videos/real-world demos.mp4" type="video/mp4">
          </video>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">Real-world Generalization Demos</h2>
          <video style="width: 90%; display: block; margin-left: auto; margin-right: auto;" controls>
            <source src="static/videos/real-world generalization demos.mp4" type="video/mp4">
          </video>
          <p class="has-text-centered" style="margin-top: 1rem;">
                Excellent generalization to variations in lighting conditions, appearance, and object position.
          </p>
      </div>
    </div>
  </div>
</section>

</body>
</html>
